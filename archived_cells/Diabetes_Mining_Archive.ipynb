{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458f35e1-3f27-4321-bfd0-9f10261b6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Lily Picchioni & Andrew Janedy\n",
    "# March 2025\n",
    "\n",
    "# Problem Statement: Diabetes in the United States. What living conditions and geographical areas within the United States can lead to an increased risk\n",
    "# of diabetes?\n",
    "\n",
    "# Background: Diabetes is a growing conern within The United States, with 37.3 million people currently diagnosed, rates of diagnosed cases of\n",
    "# diabetes has risen dramatically over the last 20 years. The disease can cause life threatening symptoms and can disrupt an individual's quality of life. \n",
    "# Our project has the potential to contribute to the public domain by identifying possible causes of the increase of diabetes in The United States. We\n",
    "# have combined multiple data sets in an attempt to find potential patterns, including data on diabetes, obesity, poverty and food security in the US.\n",
    "# Identifying potential relationships between these data sets is the first step in reducing the prevalence of this life threatening disease in the United\n",
    "# States. If we can draw significant parallels between an individuals ability to obtain quality, healthy foods, and the prevalence of conditions such as \n",
    "# obesity and diabetes, this data can be used to assist regions more likely to be impacted by these ailments.\n",
    "\n",
    "# Relevant data frames:\n",
    "# - diabetes_data: An entry for each state representing the rate of diabetes for every year between 2000-2022\n",
    "# --- Index: 'State' (The unique state name and D.C.)\n",
    "# --- Columns: XXXX (where XXXX represents the numerical year)\n",
    "# --- Values: 'Total - Percentage' (The % rate of diabetes per capita for the given year)\n",
    "\n",
    "# Exploratory Data Analysis Documentation:\n",
    "# 1. Visualizing rates of diabetes, obesity, and poverty per state from 2000 to 2020\n",
    "    # Plotting raw data is an essential part of exploratory data analysis. We plotted three graphs showing the change in each state's percentage of \n",
    "    # diabetes, obesity, and poverty from 2000 to 2020. These graphs will allow us to find patterns and trends within each state. We can also compare the\n",
    "    # three graphs to find patterns between diabetes, obesity, and poverty rates. \n",
    "# 2. Dropping Columns\n",
    "    # The poverty by state dataset originally had 500+ columns, which was reduced down to only the 33 columns that ask distinct questions\n",
    "    # and are relevant to our research. This will help us process the data further by clearing out unecessary data and making data analysis more\n",
    "    # efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2fb579-acc1-4248-ae83-0ce03b8a817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e26d587-0e7d-467d-ab4a-b68ef1726f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'Diabetes_Rates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m diabetes_data_frames \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# A list to hold the data frame for each state\u001b[39;00m\n\u001b[0;32m      9\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiabetes_Rates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# For all files in Diabetes_Rates directory\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Skip hidden/system files like .ipynb_checkpoints\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'Diabetes_Rates'"
     ]
    }
   ],
   "source": [
    "# Processes and combines diabetes rate data from multiple state-specific CSV files.\n",
    "\n",
    "# This script reads all CSV files in the \"Diabetes_Rates\" directory. It extracts the \n",
    "# state name from the filename, loads the data into a dataframe, adds a \"State\" column \n",
    "# to indicate the data's origin, and finally concatenates all state-specific \n",
    "# dataframes into a single dataframe.\n",
    "\n",
    "diabetes_data_frames = []  # A list to hold the data frame for each state\n",
    "directory = \"Diabetes_Rates\"\n",
    "\n",
    "for filename in os.listdir(directory):  # For all files in Diabetes_Rates directory\n",
    "    \n",
    "    if filename.startswith('.'):  # Skip hidden/system files like .ipynb_checkpoints\n",
    "        continue\n",
    "        \n",
    "    file_path = os.path.join(directory, filename)  # Get absolute file path\n",
    "    state = filename[:-19].replace('_', ' ')# Extract state from filepath\n",
    "    data_frame = pd.read_csv(file_path)  # Create data frame from file\n",
    "    data_frame['State'] = state  # Add column to show source state\n",
    "    diabetes_data_frames.append(data_frame)  # Add state data frame to list of data frames\n",
    "\n",
    "diabetes_data = pd.concat(diabetes_data_frames)  # Concatenate all the data frames into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a04be-a7cc-4518-af52-82da40874650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"diabetes_data contains {len(diabetes_data)} rows of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c212a-f536-4408-a5da-865e42c324fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dbdf0-ba71-429d-8a7a-e0d2b2da5a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the State, Year, and Total - Percentage columns\n",
    "\n",
    "columns_to_keep = ['State', 'Year', 'Total - Percentage']\n",
    "diabetes_data = diabetes_data[columns_to_keep]\n",
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d5ac2-9bc0-4ebe-8d82-fdfb30b56012",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711975e-f569-42d8-b6ce-0f315714dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c25844-a78f-4c3d-9ad1-95abfd622868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Join all state entries into a single entry with a column for every year\n",
    "\n",
    "# Pivot the dataframe: each state will have one row, and each year will become a separate column\n",
    "diabetes_data = diabetes_data.pivot(index='State', columns='Year', values='Total - Percentage')\n",
    "\n",
    "print(diabetes_data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa50ed0-62bb-443a-a514-1ac7c194f0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace all NaN values with the average of the previous and next available value.\n",
    "# This method does not account for back to back NaN values\n",
    "\n",
    "# Iterate over each row (state) in the dataframe\n",
    "for state in diabetes_data.index:\n",
    "    # Iterate over each column (year) for that state\n",
    "    for year in diabetes_data.columns:\n",
    "        if pd.isna(diabetes_data.loc[state, year]):  # Check if the value is NaN\n",
    "            prev_value = diabetes_data.loc[state, year - 1] if year - 1 in diabetes_data.columns else None\n",
    "            next_value = diabetes_data.loc[state, year + 1] if year + 1 in diabetes_data.columns else None\n",
    "            \n",
    "            # If both previous and next values exist, replace with their average\n",
    "            if prev_value is not None and next_value is not None:\n",
    "                diabetes_data.loc[state, year] = (prev_value + next_value) / 2\n",
    "            # If only previous value exists, use it\n",
    "            elif prev_value is not None:\n",
    "                diabetes_data.loc[state, year] = prev_value\n",
    "            # If only next value exists, use it\n",
    "            elif next_value is not None:\n",
    "                diabetes_data.loc[state, year] = next_value\n",
    "\n",
    "print(diabetes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281f980-268b-4d3a-ba43-c0d6389653a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'California' with the state you're interested in\n",
    "state_data = diabetes_data.loc['California']\n",
    "\n",
    "state_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1b907-339c-47c2-a759-e7a67357737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Loop through each state and plot its data\n",
    "for state in diabetes_data.index:\n",
    "    plt.plot(diabetes_data.columns, diabetes_data.loc[state], label=state)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total - Percentage')\n",
    "plt.title('Diabetes Total - Percentage by State Across Years')\n",
    "\n",
    "# # Rotate the x-axis labels for better readability\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"State\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()  # To ensure everything fits well in the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166ecf0-aa2f-452e-9dad-580859c20429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first and last year in the dataset\n",
    "first_year = diabetes_data.columns.min()  # Earliest year\n",
    "last_year = diabetes_data.columns.max()   # Latest year\n",
    "\n",
    "# Calculate percent change for each state\n",
    "# diabetes_data['Percent Change'] = round(((last_year.pivot - first_year.pivot) / first_year.pivot) * 100, 1)\n",
    "\n",
    "percent_change = round(((last_year - first_year) / first_year) * 100, 1)\n",
    "print(percent_change)\n",
    "# print(diabetes_data['Percent Change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4b9ed-9cd5-473b-bcd3-36ac353d230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort the dataframe for better visualization\n",
    "# pivot_df_sorted = diabetes_data.sort_values(by='Percent Change', ascending=True)\n",
    "\n",
    "# # Plot the percent change\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.bar(pivot_df_sorted.index, pivot_df_sorted['Percent Change'])\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('State')\n",
    "# plt.ylabel('Percent Change (%)')\n",
    "# plt.title('Percent Change in Total - Percentage from First to Last Year')\n",
    "# plt.xticks(rotation=90)  # Rotate state names if needed\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4b4fa-08a0-4ce6-9eb2-26ea07046d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets related to obesity and poverty in the U.S.\n",
    "# Each dataset contains state-level percentage data for different each category\n",
    "\n",
    "obesity_data = pd.read_csv(\"Obesity_Percent_by_State.csv\")\n",
    "poverty_data = pd.read_csv(\"Poverty_Percent_by_State.csv\")\n",
    "\n",
    "print(f\"obesity_data contains {len(obesity_data)} rows of data\")\n",
    "print(f\"poverty_data contains {len(poverty_data)} rows of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b9381a-2f9d-4ed6-8db4-e1f14881797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf1f5e-da7f-4052-a348-e6f79c475a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity_data.set_index(\"State\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c54c05-5d27-450c-b6a3-99d3a13ded08",
   "metadata": {},
   "outputs": [],
   "source": [
    "obesity_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a32ec-b543-4999-87ea-86ec2cc88376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean all data of missing values.  Missing values will be replaced by the average\n",
    "# of the previous and the next value.  If the missing value is the first or last\n",
    "# entry, it will be replaced with a copy of the next or previous entry, respectively\n",
    "\n",
    "\n",
    "# Ensure column names are integers\n",
    "obesity_data.columns = obesity_data.columns.astype(int)\n",
    "\n",
    "# Ensure column names are integers\n",
    "obesity_data.columns = obesity_data.columns.astype(int)\n",
    "# Iterate over each row (state) in the dataframe\n",
    "for state in obesity_data.index:\n",
    "    for year in obesity_data.columns:\n",
    "        if pd.isna(obesity_data.at[state, year]):  # Check if the value is NaN\n",
    "            prev_year = year - 1\n",
    "            next_year = year + 1\n",
    "            \n",
    "            # Get previous and next values safely\n",
    "            prev_value = obesity_data.at[state, prev_year] if prev_year in obesity_data.columns else None\n",
    "            next_value = obesity_data.at[state, next_year] if next_year in obesity_data.columns else None\n",
    "            \n",
    "            # Replace NaN with the average of previous and next values\n",
    "            if prev_value is not None and next_value is not None:\n",
    "                obesity_data.at[state, year] = (prev_value + next_value) / 2\n",
    "            elif prev_value is not None:\n",
    "                obesity_data.at[state, year] = prev_value\n",
    "            elif next_value is not None:\n",
    "                obesity_data.at[state, year] = next_value\n",
    "\n",
    "print(obesity_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bac157-c461-424a-9381-b6104b577da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Loop through each state and plot its data\n",
    "for state in obesity_data.index:\n",
    "    plt.plot(obesity_data.columns, obesity_data.loc[state], label=state)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total - Percentage')\n",
    "plt.title('Obesity Total - Percentage by State Across Years')\n",
    "\n",
    "# # Rotate the x-axis labels for better readability\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"State\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()  # To ensure everything fits well in the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae95c547-9bbc-4d2b-804d-421e8b282857",
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de2781-ad5f-488a-868c-dded0aedc3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_data.info() # Information about the poverty data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f4202-706f-49be-87fa-d56cf56fc915",
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_data.isnull().sum() # Check how many null values are in the poverty data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd70d9f-9d74-4b06-b8e9-8a51887964c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_data.set_index(\"State\", inplace=True)\n",
    "poverty_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661e42c-1c97-48e1-b465-b9bbfa0a1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we drop the '%Change' column \n",
    "plot_data = poverty_data.drop(columns=['%Change'], errors='ignore')  \n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through each state and plot its data\n",
    "for state in plot_data.index:\n",
    "    plt.plot(\n",
    "        plot_data.columns, \n",
    "        plot_data.loc[state], \n",
    "        label=state, \n",
    "        alpha=0.7,  \n",
    "        linestyle='-' if hash(state) % 2 == 0 else '--'\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total - Percentage')\n",
    "plt.title('Poverty Total - Percentage by State Across Years')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Set y-axis ticks at increments of 5 (ensuring only whole numbers)\n",
    "y_min, y_max = plt.ylim()  \n",
    "y_min = int(np.floor(y_min))  \n",
    "y_max = int(np.ceil(y_max))   \n",
    "plt.yticks(np.arange(y_min, y_max + 1, 5))  \n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"State\", bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d56542-8d66-46da-be85-3a9a093622f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets related to food security in the U.S.\n",
    "# This dataset represents U.S. census data collected in regards to, among other \n",
    "# factors, food security as it relates to finances, housing, and employment\n",
    "\n",
    "_2019_food_security_data = pd.read_csv(\"Food_Security/Food_Security_2019.csv\")\n",
    "_2020_food_security_data = pd.read_csv(\"Food_Security/Food_Security_2020.csv\")\n",
    "_2021_food_security_data = pd.read_csv(\"Food_Security/Food_Security_2021.csv\")\n",
    "_2022_food_security_data = pd.read_csv(\"Food_Security/Food_Security_2022.csv\")\n",
    "_2023_food_security_data = pd.read_csv(\"Food_Security/Food_Security_2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bef093-68c9-4a3e-9ef3-97d6f892aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_2019_food_security_data.head() # First five rows of the 2019 food security data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af93c36-c473-4929-b538-c42a3bb25ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FoodSecurityList2019 = _2019_food_security_data.columns.tolist() \n",
    "FoodSecurityList2020 = _2019_food_security_data.columns.tolist()\n",
    "FoodSecurityList2021 = _2019_food_security_data.columns.tolist()\n",
    "FoodSecurityList2022 = _2019_food_security_data.columns.tolist()\n",
    "FoodSecurityList2023 = _2019_food_security_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbd916-79b2-4083-a61d-f68583fdd156",
   "metadata": {},
   "outputs": [],
   "source": [
    "_2019_Food_Security = set(FoodSecurityList2019)  \n",
    "_2020_Food_Security = set(FoodSecurityList2020)\n",
    "_2021_Food_Security = set(FoodSecurityList2021)\n",
    "_2022_Food_Security = set(FoodSecurityList2022)\n",
    "\n",
    "# Get all unique column names across the datasets\n",
    "all_columns = _2019_Food_Security | _2020_Food_Security | _2021_Food_Security | _2022_Food_Security  # Union of all sets\n",
    "\n",
    "# Find common columns (present in all datasets)\n",
    "common_columns = _2019_Food_Security & _2020_Food_Security & _2021_Food_Security & _2022_Food_Security  # Intersection of all sets\n",
    "\n",
    "# Find unique columns (columns that appear in at least one dataset but not all)\n",
    "unique_columns = all_columns - common_columns\n",
    "\n",
    "print(f\"Number of common columns: {len(common_columns)}\")\n",
    "print(f\"Total number of columns (set): {len(all_columns)}\")\n",
    "print(f\"Columns unique to a single data set: {len(unique_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb794df4-c720-4744-824c-137b6788045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_security_dataframes = [] # List to hold food security data sets\n",
    "food_security_directory = \"Food_Security\"\n",
    "\n",
    "for filename in os.listdir(food_security_directory):\n",
    "    \n",
    "    if filename.startswith('.') or filename.endswith('.pdf'):  # Skip hidden/system files like .ipynb_checkpoints\n",
    "        continue\n",
    "        \n",
    "    file_path_2 = os.path.join(food_security_directory, filename)\n",
    "    year = filename[14:-4]\n",
    "    data_frame_2 = pd.read_csv(file_path_2)\n",
    "    data_frame_2['Year'] = year\n",
    "    food_security_dataframes.append(data_frame_2)\n",
    "\n",
    "food_security_data = pd.concat(food_security_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d8aa3-0438-415b-b791-128fafb114d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE: The scope of this dataset is described in detail in the technical document\n",
    "# .pdf files located in the Food_Security sub-directory.  The initial cleaning done \n",
    "# on this dataset by keeping a relatively small number of the original 500+ columns\n",
    "# was determined by analyzing these documents\n",
    "\n",
    "# A dictionary to contain the column names of the original data sets as keys and the \n",
    "# new names to be used for the truncated data frame.  Of the over 500 original columns\n",
    "# in the data set, only a few dozen will be considered for machine learning\n",
    "\n",
    "# Standard Key:\n",
    "#     -2 - Don't Know\n",
    "#     -3 - Refused\n",
    "#     -9 - No Response\n",
    "\n",
    "relevant_columns = {\n",
    "    'HRHHID': 'ID',  # Survey ID\n",
    "    'HRYEAR': 'Year',  # Year of record\n",
    "    'HETENURE': 'Home Owned/Rent/Other',  # Does individual rent, own, or live somewhere free\n",
    "    'HEHOUSUT': 'Housing Type',  # Type of housing unit, ie house, aparment, dorm, etc\n",
    "    'HEFAMINC': 'Household Income',  # Total household income\n",
    "    'HRNUMHOU': 'Household Size',  # Number of household occupants\n",
    "    'GEREG': 'Region',  # 1 - Northeast, 2 - Midwest, 3 - South, 4 - West\n",
    "    'GEDIV': 'Division',  # 1 - New England\n",
    "                          # 2 - Mid Atlantic\n",
    "                          # 3 - East North Central \n",
    "                          # 4 - West North Central \n",
    "                          # 5 - South Atlantic\n",
    "                          # 6 - East South Central\n",
    "                          # 7 - West South Central\n",
    "                          # 8 - Mountain\n",
    "                          # 9 - Pacific\n",
    "    'GESTFIPS': 'State Abbreviation',  # State abbreviation code\n",
    "    'PESEX': 'Sex',  # Interviewee sex\n",
    "    'PEEDUCA': 'Highest Education',  # Interviewee highest education attained1\n",
    "    'PEMJNUM': '# Jobs Held',  # Interviewee number of jobs held\n",
    "    'HES8B': 'Food Needs Met',  # Does interviewee need more money to buy food?: 1 - Yes, 2 - No & standard key\n",
    "    'HESP1': 'SNAP Benefits',  # Has interviewee or a household member recieved snap benefits?: 1 - Yes, 2 - No & standard key\n",
    "    'HES9': 'Food Security 1',  # Have you run out of money for food in the last 12 months?: 1 - Yes, 2 - No & standard key\n",
    "    'HESS1': 'Food Security 2',  # Do you often have enough desireable food in the house?: 1 - Always, 2 - Often, 3 - Sometimes, 4 - Rarely & standard key\n",
    "    'HESS2': 'Food Security 3',  # Do you worry you may run out of money for food?: 1 - Often, 2 - Sometimes, 3 - Never & standard key\n",
    "    'HESS3': 'Food Security 4',  # Have you run out of food and not had money for more?: 1 - Often, 2 - Sometimes, 3 - Never & standard key\n",
    "    'HESH2': 'Food Security 5',  # Have you had to reduce meals because of finances?: 1 - Yes, 2 - No & standard key\n",
    "    'HESH3': 'Food Security 6',  # Have you eaten less because of finances?: 1 - Yes, 2 - No & standard key\n",
    "    'HESH4': 'Food Security 7',  # Have you gone hungry due to finances?: 1 - Yes, 2 - No & standard key\n",
    "    'HESH5': 'Food Security 8',  # Have you lost weight due to finances/lack of food?: 1 - Yes, 2 - No & standard key\n",
    "    'HESS5': 'Food Security 9',  # Purchase low cost food in times of financial hardship (7-26)\n",
    "    'HESH1': 'Food Security 10',  # Children underfed in times of financial harship (7-27)\n",
    "    'HESH2': 'Food Security 11',  # Children underfed in times of financial hardship (7-28)\n",
    "    'HESSH3': 'Food Security 12',  # Children left hungry in times of financial hardship (7-30)\n",
    "    'HESSH4': 'Food Security 13',  # Children skipping meals in times of financial harship (7-31)\n",
    "    'HESSH5': 'Food Security 14',  # Children not eating for a whole day (7-33)\n",
    "    'HESC3': 'Food Security 15',  # Received food from food pantry\n",
    "    'HESC4': 'Food Security 16',  # Received meals from soup kitchen or shelter\n",
    "    'HRFS12MD': 'Food Security Status',  # Very Low (4) - High (1) food security\n",
    "    'HRFS12MC': 'Child Food Security Status',  # Very Low (3) - High (1) food security\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50501dd3-50ee-4ed4-a19a-cbd57696cdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all the columns represented as keys in the relevant_columns dictionary to the\n",
    "# value with which it is associated\n",
    "food_security_data.rename(columns=relevant_columns, inplace=True)\n",
    "\n",
    "# Create a list of the values in relevant columns, these will be the only columns in the \n",
    "# cleaned data frame\n",
    "columns_to_keep = list(relevant_columns.values())\n",
    "\n",
    "# Remove all of the superfluous columns/data\n",
    "food_security_data = food_security_data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a96504-677d-4338-8bd9-726e025ee908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"food_security_data column count: {len(food_security_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30391c23-8f67-4d11-bbaf-09fce666a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(food_security_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac676b6-90e3-461e-9200-4237cbf2d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_security_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56c7e4-d2f8-489a-ad03-a7fcb9fcad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_security_data = food_security_data.dropna(subset=['State Abbreviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef3035-1990-4ccf-b995-68302f705599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd0cf5-7cfe-4c44-88de-9cbc79111a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
